MODIJI CRAWLER:Extracted all links from a Wikipedia page, and for each link, retrieved all associated links. I navigated to Modi's wikipedia page, got all the links on that page and stored them in a blank list called links. Then, for each link in links, I created a new driver object, went to that link in order to navigate it and then stored all the links on the page of the new link in a list called lnks. After that, I cleared the lnks list for next iteration and also closed the driver object.

E-LAFDA: Utilized Web Crawling with Selenium to access Twitter, extracting the last N tweets of a controversial influencer(Elon Musk).

CERVICAL CANCER: This is a predictive model for detecting cervical cancer. Data imbalance was addressed using SMOTE for oversampling. The Random Forest model, trained on oversampled data, emerged as the best predictor, outperforming Logistic Regression and Decision Tree models in accuracy, precision, recall, and F1 score.

HOUSE PRICE PREDICTION: This is a model for predicting house sales prices.  I performed exploratory data analysis (EDA) on a house price dataset, comprising data cleaning, feature selection, and model development. Two regression models, Random Forest and Linear Regression, were trained and evaluated for predicting house prices, with the Random Forest model exhibiting superior performance in terms of mean squared error, root mean squared error, and R2 score.
